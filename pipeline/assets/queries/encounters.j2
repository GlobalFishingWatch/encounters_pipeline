CREATE TEMP FUNCTION ENCOUNTER_MAX_GAP_MINUTES() AS ({{ max_gap_minutes }});

-- adjacencies is an array of STRUCT which has seg_id, lat, lon, distance
-- need to unnest that and create a row for each adjacent segment
-- the first part of the unnested_adjacencies CTE is the first segment's track with timestamps
-- the second part gets the "encounter_" prefix and is the adjacent segment's track and distance from the first segment
-- at this point we have a bi-directional CTE, i.e. each encounter-pair exists twice, once as (A,B) and once as (B,A)
-- we will filter these down later to get unique encounter pairs
-- we need to remove invalid latitudes because the average position cannot be calculated on invalid latitudes
WITH unnested_adjacencies AS (
  SELECT
    segments.* EXCEPT(adjacent_segments),
    adjacencies.seg_id AS encounter_seg_id,
    adjacencies.lat AS encounter_lat,
    adjacencies.lon AS encounter_lon,
    adjacencies.distance AS encounter_distance
  FROM `{{ adjacency_table }}` segments
  LEFT JOIN UNNEST(adjacent_segments) adjacencies
  WHERE DATE(timestamp) BETWEEN '{{ start_date }}' AND '{{ end_date }}'
  AND segments.lat BETWEEN -90 AND 90
  AND (
    adjacencies.lat BETWEEN -90 AND 90
    OR
    adjacencies IS NULL
  )
),

-- for each segment we need to get unique timestamps so we can later check whether an encounter-pair
-- occurred after the first segment had positions which would break up the encounter sequence
segment_timestamps AS (
  SELECT DISTINCT seg_id, timestamp
  FROM unnested_adjacencies
),

segment_previous_timestamps AS (
  SELECT *, LAG(timestamp) OVER(PARTITION BY seg_id ORDER BY timestamp) segment_previous_timestamp
  FROM segment_timestamps
),

-- join back to get the previous timestamp for each segment at each timestamp
next_seg_timestamp AS (
  SELECT unnested_adjacencies.*, segment_previous_timestamps.segment_previous_timestamp
  FROM unnested_adjacencies
  LEFT JOIN segment_previous_timestamps
  USING(seg_id, timestamp)
),

previous_timestamps AS (
  SELECT *, LAG(timestamp) OVER(PARTITION BY seg_id, encounter_seg_id ORDER BY timestamp) encounter_previous_timestamp
  FROM next_seg_timestamp
),

adjacency_gaps AS (
  SELECT *, TIMESTAMP_DIFF(timestamp, encounter_previous_timestamp, MINUTE) adjacency_gap_duration
  FROM previous_timestamps
),

adjacency_ids AS (
  SELECT
  -- start a new adjacency group whenever
  -- 1. the gap duration IS NULL (i.e. new seg_id <-> encounter_seg_id combination);
  -- 2. the encounter crosses the date boundary (current bugged behaviour) --TODO: the duration exceeds the gap threshold;
  -- 3. the previous timestamp for the encounter segment is not the same as the previous timestamp for the segment
  --    (i.e. the segment had positions in between the current and previous encounter position)
    CASE
      WHEN adjacency_gap_duration IS NULL
        OR DATE(encounter_previous_timestamp) != DATE(timestamp)
        OR segment_previous_timestamp != encounter_previous_timestamp
      THEN 1
      ELSE 0
    END AS adjacency_group_indicator,
    *
  FROM adjacency_gaps
),

adjacency_groups AS (
  SELECT SUM(adjacency_group_indicator) OVER(PARTITION BY seg_id, encounter_seg_id ORDER BY timestamp) AS adjacency_group_index, *
  FROM adjacency_ids
),

-- TODO: all of those aggregations need to be adjusted and implied speed needs to be added
encounters AS (
  SELECT MIN(timestamp) start_time, MAX(timestamp) end_time, seg_id, encounter_seg_id, adjacency_group_index, ST_CENTROID_AGG(ST_geogpoint(lon,lat)) avg_lat_lon
  FROM adjacency_groups
  GROUP BY seg_id, encounter_seg_id, adjacency_group_index
),

-- until here, what we've done is equivalent to compute_encounters and writing raw_encounters
-- the rest below is equivalent to merge_encounters
gc AS (
  SELECT format("lon:%+07.2f_lat:%+07.2f", ST_X(avg_lat_lon), ST_Y(avg_lat_lon)) as gridcode, * FROM encounters
),

filtered_encounters AS (
  SELECT * REPLACE(
    LEAST(seg_id, encounter_seg_id) AS seg_id,
    GREATEST(seg_id, encounter_seg_id) AS encounter_seg_id
  ) FROM gc
  JOIN  `global-fishing-watch.pipe_static.spatial_measures_clustered_20230307`
  USING (gridcode)
  WHERE TIMESTAMP_DIFF(end_time, start_time, MINUTE) >= 120
  AND distance_from_port_m >= 10000
  AND distance_from_shore_m > 0
  AND seg_id NOT IN (SELECT seg_id FROM {{ bad_segs_table }})
  AND encounter_seg_id NOT IN (SELECT seg_id FROM {{ bad_segs_table }})
),

intervals AS (
  SELECT 
    *,
    MAX(end_time) OVER (PARTITION BY seg_id, encounter_seg_id ORDER BY start_time, end_time
      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING
    ) AS max_end_so_far
  FROM filtered_encounters
),

interval_groups AS (
  SELECT 
    *,
    COUNTIF(start_time > max_end_so_far) OVER (PARTITION BY seg_id, encounter_seg_id ORDER BY start_time, end_time) AS group_id
  FROM intervals
),

encounter_groups AS (
  SELECT *, COUNTIF(TIMESTAMP_DIFF(start_time, max_end_so_far, MINUTE) >= 4 * 60) OVER (PARTITION BY seg_id, encounter_seg_id ORDER BY start_time, end_time) AS merged_encounter_group
  FROM interval_groups
),

merged_encounters AS (
  SELECT 
    MIN(start_time) start_time,
    MAX(end_time) end_time,
    seg_id,
    encounter_seg_id,
    merged_encounter_group,
    ST_CENTROID_AGG(avg_lat_lon) avg_lat_lon,
    AVG(distance_from_port_m) avg_distance_from_port_m,
  FROM encounter_groups
  GROUP BY seg_id, encounter_seg_id, merged_encounter_group
)

SELECT * FROM merged_encounters
